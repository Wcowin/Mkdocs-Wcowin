# å¤‡ä»½æ™ºèƒ½æ‘˜è¦ä»£ç 
import re
import json
import hashlib
import requests
from pathlib import Path
from datetime import datetime
from functools import lru_cache

class AISummaryGenerator:
    def __init__(self):
        self.cache_dir = Path("site/.ai_cache")
        self.cache_dir.mkdir(exist_ok=True)
        
        # DeepSeek APIé…ç½®
        self.api_config = {
            'url': 'https://api.deepseek.com/v1/chat/completions',
            'model': 'deepseek-chat',
            'headers': {
                'Content-Type': 'application/json',
                'Authorization': 'Bearer sk-'
            }
        }
        
        # ğŸ“‚ å¯è‡ªå®šä¹‰çš„æ–‡ä»¶å¤¹é…ç½®
        self.enabled_folders = [
            'blog/',      # blogæ–‡ä»¶å¤¹
            'develop/',   # developæ–‡ä»¶å¤¹
            # 'about/',    # aboutæ–‡ä»¶å¤¹
            # åœ¨è¿™é‡Œæ·»åŠ æ‚¨æƒ³è¦å¯ç”¨AIæ‘˜è¦çš„æ–‡ä»¶å¤¹
        ]
        
        # ğŸ“‹ æ’é™¤çš„æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
        self.exclude_patterns = [
            'liuyanban.md', 'link.md', '404.md', 'tag.md', 'tags.md',
            '/about/', '/search/', '/sitemap', 'index.md',  # æ ¹ç›®å½•index.md
        ]
        
        # ğŸ“‹ æ’é™¤çš„ç‰¹å®šæ–‡ä»¶
        self.exclude_files = [
            'blog/index.md',
            'blog/indexblog.md',
            'docs/index.md',
            'develop/index.md',
        ]
    
    def configure_folders(self, folders=None, exclude_patterns=None, exclude_files=None):
        """
        é…ç½®å¯ç”¨AIæ‘˜è¦çš„æ–‡ä»¶å¤¹
        
        Args:
            folders: å¯ç”¨AIæ‘˜è¦çš„æ–‡ä»¶å¤¹åˆ—è¡¨
            exclude_patterns: æ’é™¤çš„æ¨¡å¼åˆ—è¡¨  
            exclude_files: æ’é™¤çš„ç‰¹å®šæ–‡ä»¶åˆ—è¡¨
        """
        if folders is not None:
            self.enabled_folders = folders
        if exclude_patterns is not None:
            self.exclude_patterns = exclude_patterns
        if exclude_files is not None:
            self.exclude_files = exclude_files
    
    def get_content_hash(self, content):
        """ç”Ÿæˆå†…å®¹hashç”¨äºç¼“å­˜"""
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def get_cached_summary(self, content_hash):
        """è·å–ç¼“å­˜çš„æ‘˜è¦"""
        cache_file = self.cache_dir / f"{content_hash}.json"
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆ7å¤©ï¼‰
                    cache_time = datetime.fromisoformat(cache_data.get('timestamp', '1970-01-01'))
                    if (datetime.now() - cache_time).days < 7:
                        return cache_data
            except:
                pass
        return None
    
    def save_summary_cache(self, content_hash, summary_data):
        """ä¿å­˜æ‘˜è¦åˆ°ç¼“å­˜"""
        cache_file = self.cache_dir / f"{content_hash}.json"
        try:
            summary_data['timestamp'] = datetime.now().isoformat()
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜æ‘˜è¦ç¼“å­˜å¤±è´¥: {e}")
    
    def clean_content_for_ai(self, markdown):
        """æ¸…ç†å†…å®¹ï¼Œæå–ä¸»è¦æ–‡æœ¬ç”¨äºAIå¤„ç†"""
        content = markdown
        
        # ç§»é™¤YAML front matter
        content = re.sub(r'^---.*?---\s*', '', content, flags=re.DOTALL)
        
        # ç§»é™¤å·²å­˜åœ¨çš„é˜…è¯»ä¿¡æ¯å—å’ŒAIæ‘˜è¦å—
        content = re.sub(r'!!! info "ğŸ“– é˜…è¯»ä¿¡æ¯".*?(?=\n\n|\n#|\Z)', '', content, flags=re.DOTALL)
        content = re.sub(r'!!! info "ğŸ¤– AIæ™ºèƒ½æ‘˜è¦".*?(?=\n\n|\n#|\Z)', '', content, flags=re.DOTALL)
        content = re.sub(r'!!! tip "ğŸ“ è‡ªåŠ¨æ‘˜è¦".*?(?=\n\n|\n#|\Z)', '', content, flags=re.DOTALL)
        
        # ç§»é™¤HTMLæ ‡ç­¾
        content = re.sub(r'<[^>]+>', '', content)
        
        # ç§»é™¤å›¾ç‰‡ï¼Œä¿ç•™altæ–‡æœ¬ä½œä¸ºå†…å®¹æç¤º
        content = re.sub(r'!\[([^\]]*)\]\([^)]+\)', r'[å›¾ç‰‡ï¼š\1]', content)
        
        # ç§»é™¤é“¾æ¥ï¼Œä¿ç•™æ–‡æœ¬
        content = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', content)
        
        # ç§»é™¤ä»£ç å—ï¼Œä½†ä¿ç•™å…³é”®ä¿¡æ¯
        content = re.sub(r'```(\w+)?\n(.*?)\n```', r'[ä»£ç ç¤ºä¾‹]', content, flags=re.DOTALL)
        
        # ç§»é™¤è¡Œå†…ä»£ç 
        content = re.sub(r'`[^`]+`', '[ä»£ç ]', content)
        
        # ç§»é™¤è¡¨æ ¼æ ¼å¼ä½†ä¿ç•™å†…å®¹
        content = re.sub(r'\|[^\n]+\|', '', content)
        content = re.sub(r'^[-|:\s]+$', '', content, flags=re.MULTILINE)
        
        # æ¸…ç†æ ¼å¼ç¬¦å·
        content = re.sub(r'\*\*([^*]+)\*\*', r'\1', content)  # ç²—ä½“
        content = re.sub(r'\*([^*]+)\*', r'\1', content)      # æ–œä½“
        content = re.sub(r'^#+\s*', '', content, flags=re.MULTILINE)  # æ ‡é¢˜ç¬¦å·
        
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œå’Œç©ºæ ¼
        content = re.sub(r'\n\s*\n', '\n\n', content)
        content = re.sub(r'^[ \t]+', '', content, flags=re.MULTILINE)
        content = content.strip()
        
        return content
    
    def generate_ai_summary(self, content, page_title=""):
        """ä½¿ç”¨DeepSeekç”Ÿæˆæ‘˜è¦"""
        # ä¼˜åŒ–çš„æç¤ºè¯
        prompt = f"""è¯·ä¸ºä»¥ä¸‹æŠ€æœ¯æ–‡ç« ç”Ÿæˆä¸€ä¸ªé«˜è´¨é‡çš„æ‘˜è¦ï¼Œè¦æ±‚ï¼š

1. **é•¿åº¦æ§åˆ¶**ï¼šä¸¥æ ¼æ§åˆ¶åœ¨80-120å­—ä»¥å†…
2. **å†…å®¹è¦æ±‚**ï¼š
   - å‡†ç¡®æ¦‚æ‹¬æ–‡ç« çš„æ ¸å¿ƒä¸»é¢˜å’Œå…³é”®è¦ç‚¹
   - çªå‡ºæŠ€æœ¯ç‰¹ç‚¹ã€åº”ç”¨åœºæ™¯æˆ–è§£å†³çš„é—®é¢˜
   - ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€
   - é¿å…é‡å¤æ–‡ç« æ ‡é¢˜çš„å†…å®¹
3. **æ ¼å¼è¦æ±‚**ï¼š
   - ç›´æ¥è¿”å›æ‘˜è¦å†…å®¹ï¼Œæ— éœ€ä»»ä½•å‰ç¼€æˆ–åç¼€
   - ä½¿ç”¨ç®€æ´çš„é™ˆè¿°å¥
   - å¯ä»¥é€‚å½“ä½¿ç”¨æŠ€æœ¯æœ¯è¯­

æ–‡ç« æ ‡é¢˜ï¼š{page_title}

æ–‡ç« å†…å®¹ï¼š
{content[:2500]}

è¯·ç”Ÿæˆæ‘˜è¦ï¼š"""

        try:
            payload = {
                "model": self.api_config['model'],
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£æ‘˜è¦ä¸“å®¶ï¼Œæ“…é•¿æå–æ–‡ç« æ ¸å¿ƒè¦ç‚¹å¹¶ç”Ÿæˆç®€æ´å‡†ç¡®çš„æ‘˜è¦ã€‚"
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                "max_tokens": 150,
                "temperature": 0.3,  # é™ä½éšæœºæ€§ï¼Œæé«˜å‡†ç¡®æ€§
                "top_p": 0.9
            }
            
            response = requests.post(
                self.api_config['url'],
                headers=self.api_config['headers'],
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                summary = result['choices'][0]['message']['content'].strip()
                
                # æ¸…ç†å¯èƒ½çš„æ ¼å¼é—®é¢˜
                summary = re.sub(r'^["""''`]+|["""''`]+$', '', summary)
                summary = re.sub(r'^\s*æ‘˜è¦[ï¼š:]\s*', '', summary)
                summary = re.sub(r'^\s*æ€»ç»“[ï¼š:]\s*', '', summary)
                
                return summary
            else:
                print(f"DeepSeek APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"DeepSeek APIè¯·æ±‚å¼‚å¸¸: {e}")
            return None
        except Exception as e:
            print(f"AIæ‘˜è¦ç”Ÿæˆå¼‚å¸¸: {e}")
            return None
    
    def generate_fallback_summary(self, content, page_title=""):
        """ç”Ÿæˆå¤‡ç”¨æ‘˜è¦ï¼ˆåŸºäºè§„åˆ™çš„æ™ºèƒ½æ‘˜è¦ï¼‰"""
        # ç§»é™¤æ ¼å¼ç¬¦å·
        clean_text = re.sub(r'^#+\s*', '', content, flags=re.MULTILINE)
        clean_text = re.sub(r'\*\*([^*]+)\*\*', r'\1', clean_text)
        clean_text = re.sub(r'\*([^*]+)\*', r'\1', clean_text)
        
        # åˆ†å‰²æˆå¥å­
        sentences = re.split(r'[\u3002\uff01\uff1f.!?]', clean_text)
        sentences = [s.strip() for s in sentences if len(s.strip()) > 15]
        
        # ä¼˜å…ˆé€‰æ‹©åŒ…å«å…³é”®è¯çš„å¥å­
        key_indicators = [
            'ä»‹ç»', 'è®²è§£', 'è¯´æ˜', 'åˆ†æ', 'æ¢è®¨', 'ç ”ç©¶', 'å®ç°', 'åº”ç”¨',
            'æ–¹æ³•', 'æŠ€æœ¯', 'ç®—æ³•', 'åŸç†', 'æ¦‚å¿µ', 'ç‰¹ç‚¹', 'ä¼˜åŠ¿', 'è§£å†³',
            'æ•™ç¨‹', 'æŒ‡å—', 'é…ç½®', 'å®‰è£…', 'éƒ¨ç½²', 'å¼€å‘', 'è®¾è®¡', 'æ„å»º'
        ]
        
        priority_sentences = []
        normal_sentences = []
        
        for sentence in sentences[:10]:  # å¤„ç†å‰10å¥
            if any(keyword in sentence for keyword in key_indicators):
                priority_sentences.append(sentence)
            else:
                normal_sentences.append(sentence)
        
        # ç»„åˆæ‘˜è¦
        selected_sentences = []
        total_length = 0
        
        # ä¼˜å…ˆä½¿ç”¨å…³é”®å¥å­
        for sentence in priority_sentences:
            if total_length + len(sentence) > 100:
                break
            selected_sentences.append(sentence)
            total_length += len(sentence)
        
        # å¦‚æœè¿˜æœ‰ç©ºé—´ï¼Œæ·»åŠ æ™®é€šå¥å­
        if total_length < 80:
            for sentence in normal_sentences:
                if total_length + len(sentence) > 100:
                    break
                selected_sentences.append(sentence)
                total_length += len(sentence)
        
        if selected_sentences:
            summary = '.'.join(selected_sentences) + '.'
            # ç®€åŒ–å†—é•¿çš„æ‘˜è¦
            if len(summary) > 120:
                summary = selected_sentences[0] + '.'
            return summary
        else:
            # æ ¹æ®æ ‡é¢˜ç”Ÿæˆé€šç”¨æ‘˜è¦
            if any(keyword in page_title for keyword in ['æ•™ç¨‹', 'æŒ‡å—', 'Tutorial']):
                return 'æœ¬æ–‡æä¾›äº†è¯¦ç»†çš„æ•™ç¨‹æŒ‡å—ï¼Œé€šè¿‡å®ä¾‹æ¼”ç¤ºå¸®åŠ©è¯»è€…æŒæ¡ç›¸å…³æŠ€æœ¯è¦ç‚¹ã€‚'
            elif any(keyword in page_title for keyword in ['é…ç½®', 'è®¾ç½®', 'å®‰è£…', 'Config']):
                return 'æœ¬æ–‡ä»‹ç»äº†ç³»ç»Ÿé…ç½®çš„æ–¹æ³•å’Œæ­¥éª¤ï¼Œæä¾›å®ç”¨çš„è®¾ç½®å»ºè®®å’Œæœ€ä½³å®è·µã€‚'
            elif any(keyword in page_title for keyword in ['å¼€å‘', 'ç¼–ç¨‹', 'Development']):
                return 'æœ¬æ–‡åˆ†äº«äº†å¼€å‘ç»éªŒå’ŒæŠ€æœ¯å®è·µï¼Œæä¾›äº†å®ç”¨çš„ä»£ç ç¤ºä¾‹å’Œè§£å†³æ–¹æ¡ˆã€‚'
            else:
                return 'æœ¬æ–‡æ·±å…¥æ¢è®¨äº†ç›¸å…³æŠ€æœ¯å†…å®¹ï¼Œæä¾›äº†å®ç”¨çš„æ–¹æ³•å’Œè§£å†³æ–¹æ¡ˆã€‚'
    
    def process_page(self, markdown, page, config):
        """å¤„ç†é¡µé¢ï¼Œç”ŸæˆAIæ‘˜è¦"""
        if not self.should_generate_summary(page, markdown):
            return markdown
        
        clean_content = self.clean_content_for_ai(markdown)
        
        # å†…å®¹é•¿åº¦æ£€æŸ¥
        if len(clean_content) < 200:
            print(f"ğŸ“„ å†…å®¹å¤ªçŸ­ï¼Œè·³è¿‡æ‘˜è¦ç”Ÿæˆ: {page.file.src_path}")
            return markdown
        
        content_hash = self.get_content_hash(clean_content)
        page_title = getattr(page, 'title', '')
        
        # æ£€æŸ¥ç¼“å­˜
        cached_summary = self.get_cached_summary(content_hash)
        if cached_summary:
            summary = cached_summary.get('summary', '')
            ai_service = 'cached'
            print(f"âœ… ä½¿ç”¨ç¼“å­˜æ‘˜è¦: {page.file.src_path}")
        else:
            # ç”Ÿæˆæ–°æ‘˜è¦
            print(f"ğŸ¤– æ­£åœ¨ç”ŸæˆAIæ‘˜è¦: {page.file.src_path}")
            summary = self.generate_ai_summary(clean_content, page_title)
            
            if not summary:
                summary = self.generate_fallback_summary(clean_content, page_title)
                ai_service = 'fallback'
                print(f"ğŸ“ ä½¿ç”¨å¤‡ç”¨æ‘˜è¦: {page.file.src_path}")
            else:
                ai_service = 'deepseek'
                print(f"âœ… AIæ‘˜è¦ç”ŸæˆæˆåŠŸ: {page.file.src_path}")
            
            # ä¿å­˜åˆ°ç¼“å­˜
            self.save_summary_cache(content_hash, {
                'summary': summary,
                'service': ai_service,
                'page_title': page_title
            })
        
        # æ·»åŠ æ‘˜è¦åˆ°é¡µé¢æœ€ä¸Šé¢
        summary_html = self.format_summary(summary, ai_service)
        return summary_html + '\n\n' + markdown
    
    def should_generate_summary(self, page, markdown):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç”Ÿæˆæ‘˜è¦ - å¯è‡ªå®šä¹‰æ–‡ä»¶å¤¹"""
        # æ£€æŸ¥é¡µé¢å…ƒæ•°æ®
        if hasattr(page, 'meta'):
            # æ˜ç¡®ç¦ç”¨
            if page.meta.get('ai_summary') == False:
                return False
            
            # å¼ºåˆ¶å¯ç”¨
            if page.meta.get('ai_summary') == True:
                return True
        
        # è·å–æ–‡ä»¶è·¯å¾„
        src_path = page.file.src_path.replace('\\', '/')  # ç»Ÿä¸€è·¯å¾„åˆ†éš”ç¬¦
        
        # æ£€æŸ¥æ’é™¤æ¨¡å¼
        if any(pattern in src_path for pattern in self.exclude_patterns):
            return False
        
        # æ£€æŸ¥æ’é™¤çš„ç‰¹å®šæ–‡ä»¶
        if src_path in self.exclude_files:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å¯ç”¨çš„æ–‡ä»¶å¤¹ä¸­
        for folder in self.enabled_folders:
            if src_path.startswith(folder) or f'/{folder}' in src_path:
                folder_name = folder.rstrip('/')
                print(f"ğŸ¯ {folder_name}æ–‡ä»¶å¤¹æ–‡ç« æ£€æµ‹åˆ°ï¼Œå¯ç”¨AIæ‘˜è¦: {src_path}")
                return True
        
        # é»˜è®¤ä¸ç”Ÿæˆæ‘˜è¦
        return False
    
    def format_summary(self, summary, ai_service):
        """æ ¼å¼åŒ–æ‘˜è¦æ˜¾ç¤º"""
        service_config = {
            'deepseek': {
                'icon': 'ğŸ¤–',
                'name': 'AIæ™ºèƒ½æ‘˜è¦',
                'color': 'info'
            },
            'fallback': {
                'icon': 'ğŸ“',
                'name': 'è‡ªåŠ¨æ‘˜è¦',
                'color': 'tip'
            },
            'cached': {
                'icon': 'ğŸ’¾',
                'name': 'AIæ™ºèƒ½æ‘˜è¦',
                'color': 'info'
            }
        }
        
        config = service_config.get(ai_service, service_config['deepseek'])
        
        return f'''??? {config['color']} "{config['icon']} {config['name']}"
    {summary}

'''

# åˆ›å»ºå…¨å±€å®ä¾‹
ai_summary_generator = AISummaryGenerator()

# ğŸ”§ è‡ªå®šä¹‰é…ç½®å‡½æ•°
def configure_ai_summary(enabled_folders=None, exclude_patterns=None, exclude_files=None):
    """
    é…ç½®AIæ‘˜è¦åŠŸèƒ½
    
    Args:
        enabled_folders: å¯ç”¨AIæ‘˜è¦çš„æ–‡ä»¶å¤¹åˆ—è¡¨ï¼Œä¾‹å¦‚ ['blog/', 'docs/', 'posts/']
        exclude_patterns: æ’é™¤çš„æ¨¡å¼åˆ—è¡¨ï¼Œä¾‹å¦‚ ['404.md', '/admin/']
        exclude_files: æ’é™¤çš„ç‰¹å®šæ–‡ä»¶åˆ—è¡¨ï¼Œä¾‹å¦‚ ['blog/index.md']
    
    Example:
        # åªåœ¨blogå’Œdocsæ–‡ä»¶å¤¹å¯ç”¨
        configure_ai_summary(['blog/', 'docs/'])
        
        # åœ¨æ‰€æœ‰æ–‡ä»¶å¤¹å¯ç”¨ï¼Œä½†æ’é™¤ç‰¹å®šæ–‡ä»¶
        configure_ai_summary([''], exclude_files=['index.md', 'about.md'])
    """
    ai_summary_generator.configure_folders(enabled_folders, exclude_patterns, exclude_files)

def on_page_markdown(markdown, page, config, files):
    """MkDocs hookå…¥å£ç‚¹"""
    return ai_summary_generator.process_page(markdown, page, config)

